# AI on Containers - Demo

## About

This repository demonstrates how to leverage **Google Kubernetes Engine (GKE)** for distributed AI/ML training and **Cloud Run** for model serving. It showcases best practices such as:
- Containerizing PyTorch training and inference scripts.
- Using Google Cloud Build for CI/CD.
- Distributed Data Parallel (DDP) training on GKE using Indexed Jobs.
- Storing artifacts in Google Cloud Storage (GCS).
- Serving models securely and efficiently on Cloud Run.

## Directory Structure
```
aioc-demo/
├── trainer/                # Training component
│   ├── train.py            # PyTorch training script (DDP enabled)
│   ├── Dockerfile          # Dockerfile for training image
│   └── requirements.txt    # Training dependencies
├── serving/                # Serving component
│   ├── app.py              # Flask inference app
│   ├── Dockerfile          # Dockerfile for serving image
│   └── requirements.txt    # Serving dependencies
├── k8s/                    # Kubernetes manifests
│   └── job.yaml            # GKE Indexed Job for distributed training
├── cloudbuild.yaml         # Cloud Build CI/CD pipeline configuration
└── README.md
```

## Prerequisites

- Google Cloud Project
- Docker (optional, for local testing)
- `gcloud` CLI installed and configured

## Setup

### 1. Environment Setup

Define your environment variables:
```bash
export PROJECT_ID=aioc-demo
export REGION=us-west1
export GAR_REPO=aioc-docker-repo
export BUCKET_NAME=aioc-demo-bucket
export CLUSTER_NAME=aioc-cluster
```

Initialize your project:
```bash
gcloud config set project ${PROJECT_ID}

# Enable APIs
gcloud services enable \
    artifactregistry.googleapis.com \
    storage-api.googleapis.com \
    run.googleapis.com \
    container.googleapis.com \
    cloudbuild.googleapis.com
```

### 2. Infrastructure Creation

**Artifact Registry:**
```bash
gcloud artifacts repositories create ${GAR_REPO} \
    --repository-format=docker \
    --location=${REGION}
```

**GCS Bucket:**
```bash
gcloud storage buckets create gs://${BUCKET_NAME} --location=${REGION}
```

**Service Account & Workload Identity:**
Create a Service Account for training:
```bash
gcloud iam service-accounts create aioc-training-sa --display-name="AIoC Training SA"

# Grant storage admin access (for demo purposes; restrict in production)
gcloud projects add-iam-policy-binding ${PROJECT_ID} \
    --member="serviceAccount:aioc-training-sa@${PROJECT_ID}.iam.gserviceaccount.com" \
    --role="roles/storage.objectAdmin"
```

**GKE Cluster (Autopilot or Standard):**
```bash
gcloud container clusters create-auto ${CLUSTER_NAME} \
    --region=${REGION} \
    --project=${PROJECT_ID}
```

**Configure Workload Identity for GKE:**
```bash
# Allow Kubernetes ServiceAccount to impersonate Google Service Account
gcloud iam service-accounts add-iam-policy-binding aioc-training-sa@${PROJECT_ID}.iam.gserviceaccount.com \
    --role roles/iam.workloadIdentityUser \
    --member "serviceAccount:${PROJECT_ID}.svc.id.goog[default/aioc-training-sa]"
```

*Note: The `k8s/job.yaml` expects a Kubernetes ServiceAccount named `aioc-training-sa`.*

### 3. Build & Deploy

You can use Cloud Build to build images and prepare manifests.

**Submit Build:**
```bash
gcloud builds submit --config=cloudbuild.yaml \
    --substitutions=_REGION=${REGION},_GAR_REPO=${GAR_REPO},_BUCKET_NAME=${BUCKET_NAME}
```

**Run Training Job:**
Apply the rendered manifest (after inspecting `k8s/job_rendered.yaml` generated by build, or manually substitute):
```bash
# Example manual substitution if not using Cloud Build to deploy
sed -e "s|\\
${IMAGE_URI}\\|${REGION}-docker.pkg.dev/${PROJECT_ID}/${GAR_REPO}/aioc-training:latest|g" \
    -e "s|\\
${BUCKET_NAME}\\|${BUCKET_NAME}|g" \
    k8s/job.yaml | kubectl apply -f - 
```

**Deploy Serving to Cloud Run:**
```bash
gcloud run deploy aioc-serving \
    --image=${REGION}-docker.pkg.dev/${PROJECT_ID}/${GAR_REPO}/aioc-serving:latest \
    --region=${REGION} \
    --platform=managed \
    --allow-unauthenticated \
    --set-env-vars=BUCKET_NAME=${BUCKET_NAME}
```

## Architecture Notes
- **Training**: Uses PyTorch `DistributedDataParallel`. The GKE Job is configured as an `Indexed` Job to provide stable hostnames (via Headless Service) and unique indices (`RANK`) to each pod.
- **Serving**: Uses Flask + Gunicorn. On startup, it checks the GCS bucket for the trained model. If found, it downloads it; otherwise, it falls back to a default pre-trained model.